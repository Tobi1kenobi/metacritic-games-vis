{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling all the reviews for a specific game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\"\n",
    "headers = {'User-Agent':user_agent}\n",
    "justcause4_rev = requests.get(\"https://www.metacritic.com/game/playstation-4/god-of-war/critic-reviews\",\n",
    "                         headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "justcause4_details = requests.get(\"https://www.metacritic.com/game/playstation-4/god-of-war/details\",\n",
    "                         headers = headers)\n",
    "jc4_detail_soup = BeautifulSoup(justcause4_details.content, 'html.parser')\n",
    "jc4_detail_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting franchise\n",
    "def GetFranchise(detail_soup):\n",
    "    franchise_js = detail_soup.find('script', {\"type\":\"text/javascript\",\n",
    "                                                    \"src\":\"https://urs.metacritic.com/sdk/urs.js\"}).previous_sibling.previous_sibling\n",
    "    franchise_text = franchise_js.get_text().strip().split(';')\n",
    "    for element in franchise_text:\n",
    "        element = element.strip()\n",
    "    #     print(element,'\\n')\n",
    "        if re.match(re.compile('MetaC.Video.setIMATargeting\\(\\\"franchise*'), element):\n",
    "            match = element\n",
    "            match = match.split(',')[-1].strip().strip('\\)').strip('\\\"')\n",
    "            match = match.replace('-', ' ')\n",
    "            return(match)\n",
    "\n",
    "GetFranchise(jc4_detail_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc4_rev_soup = BeautifulSoup(justcause4_rev.content, 'html.parser')\n",
    "#jc4_reviews = jc4_soup.find_all('a', text='Read full review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc4_review_metas = jc4_rev_soup.find_all('li', {\"class\":\"review critic_review\"})\n",
    "review_score_dict = {}\n",
    "review_summary_dict = {}\n",
    "\n",
    "for rev in jc4_review_metas:\n",
    "    try:\n",
    "        cur_rev_critic = rev.find('div', {\"class\":\"review_critic\"}).find('a').get_text().strip()\n",
    "    except:\n",
    "        cur_rev_critic = rev.find('div', {\"class\":\"review_critic\"}).find('div').get_text().strip()\n",
    "    cur_rev_summary = rev.find('div', {\"class\":\"review_body\"}).get_text().strip()\n",
    "    cur_rev_score = rev.find('div', {\"class\":\"review_grade\"}).get_text().strip()\n",
    "    review_summary_dict[cur_rev_critic] = cur_rev_summary\n",
    "    review_score_dict[cur_rev_critic] = cur_rev_score\n",
    "\n",
    "review_summary_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc4_review_links = [a.get('href') for a in jc4_rev_soup.find_all('a', href=True, text='Read full review')]\n",
    "jc4_review_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_cause4 = requests.get(\"https://www.metacritic.com/game/playstation-4/just-cause-4/\",\n",
    "                         headers = headers)\n",
    "jc4_soup = BeautifulSoup(just_cause4.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc4_pub = jc4_detail_soup.find_all('a', {'href': re.compile(r'/company')})[1].get_text().strip()\n",
    "jc4_details = jc4_detail_soup.find_all('th', scope='row')\n",
    "jc4_details[1].get_text().strip(':')\n",
    "jc4_deets = {}\n",
    "for detail in jc4_details:\n",
    "    if detail.get_text() == \"ESRB Descriptors:\":\n",
    "        print('ESRB')\n",
    "        value = detail.next_sibling.get_text().strip()\n",
    "    elif detail.get_text() == \"Number of Online Players:\":\n",
    "        value = detail.next_sibling.get_text().strip()\n",
    "    elif detail.get_text() == \"Genre(s):\":\n",
    "        value = detail.next_sibling.next_sibling.get_text().split(',')\n",
    "        for i in range(len(value)):\n",
    "            value[i] = value[i].strip()\n",
    "    else:\n",
    "        if detail.next_sibling.next_sibling == None:\n",
    "            print(detail)\n",
    "        value = detail.next_sibling.next_sibling.get_text().strip()\n",
    "    jc4_deets[detail.get_text().strip(':')] = value\n",
    "    \n",
    "print(jc4_deets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.gamerevolution.com/review/467609-just-cause-4-review-a-cause-for-celebration\")\n",
    "page.status_code == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "body = soup.find('body')\n",
    "the_contents_of_body_without_body_tags = body.find_all('p')\n",
    "string = \"\"\n",
    "for i in the_contents_of_body_without_body_tags:\n",
    "    string += i.get_text()\n",
    "    string += \" \"\n",
    "    \n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_review_text = {}\n",
    "\n",
    "for link in jc4_review_links:\n",
    "    page = requests.get(link)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    body = soup.find('body')\n",
    "    body_content = body.find_all('p')\n",
    "    review_string = \"\"\n",
    "    for i in body_content:\n",
    "        review_string += i.get_text()\n",
    "        review_string += \" \"\n",
    "    all_review_text[link] = review_string\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the review text into a list of words\n",
    "all_reviews_string = \"\\n\".join(all_review_text.values())\n",
    "all_review_words = all_reviews_string.split()\n",
    "review_words = []\n",
    "for word in all_review_words:\n",
    "    cur_word = word.rstrip(' .,')\n",
    "    review_words.append(cur_word)\n",
    "review_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_review_words = []\n",
    "for word in review_words:\n",
    "    if word in list_of_adjectives:\n",
    "        filtered_review_words.append(word)\n",
    "jc4_adjectives = ' '.join(filtered_review_words)\n",
    "jc4_adjectives = jc4_adjectives.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"Data/jc4.txt\", jc4_adjectives, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing the above for all games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\"\n",
    "headers = {'User-Agent':user_agent}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in list of all games\n",
    "meta_games = pd.read_csv('../Data/result.csv')\n",
    "\n",
    "meta_games.sort_values(by='metascore',ascending=False).head(20)\n",
    "#np.unique(meta_games['console'])\n",
    "\n",
    "# Making a copy of the datafram that I will mutate\n",
    "meta_games_copy = meta_games.copy()\n",
    "\n",
    "# Adding new columns for genre, publisher, etc\n",
    "details = [\"genre(s)\",\"developer\",\"players\",\"publisher\",\"rating\"] \n",
    "extra_details = [\"ESRB Descriptors:\", \"Number of Online Players:\", \"Special Controllers:\", \"Number of Players:\"]\n",
    "\n",
    "for new_col in details + extra_details + ['official site']:\n",
    "    new_col = new_col.strip(':').lower()\n",
    "    meta_games_copy[new_col] = np.\n",
    "    \n",
    "list(meta_games_copy.columns)[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAYBE DONT EVEN NEED TO MERGE, JUST USE READ IN CSV\n",
    "\n",
    "extra_up_until_now = pd.read_csv(\"../Data/extra_details_complete.csv\", index_col=0).replace('<built-in function empty>', np.empty)\n",
    "extra_up_until_now['developer'][30]\n",
    "meta_games_new = pd.merge(meta_games_copy,extra_up_until_now, how='right')\n",
    "print(len(meta_games_copy),len(meta_games_new))\n",
    "print(meta_games_copy.head(5),'\\n\\n')\n",
    "print(extra_up_until_now.head(5),'\\n\\n')\n",
    "print(meta_games_new.head(5),'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def URLMaker(name,platform,end=\"\"):\n",
    "    base_url = 'https://www.metacritic.com/game'\n",
    "    platform_dict = {'PS':'playstation',\n",
    "                    'PS2':'playstation-2',\n",
    "                    'PS3':'playstation-3',\n",
    "                    'PS4':'playstation-4',\n",
    "                    'X360':'xbox-360',\n",
    "                    'XBOX':'xbox',\n",
    "                    'PC':'pc',\n",
    "                    'VITA':'playstation-vita',\n",
    "                    '3DS':'3ds',\n",
    "                    'DC':'dreamcast',\n",
    "                    'DS':'ds',\n",
    "                    'GBA':'game-boy-advance',\n",
    "                    'GC':'gamecube',\n",
    "                    'N64':'nintendo-64',\n",
    "                    'PSP':'psp',\n",
    "                    'Switch':'switch',\n",
    "                    'WII':'wii',\n",
    "                    'WIIU':'wii-u',\n",
    "                    'XONE':'xbox-one'}\n",
    "    full_platform = platform_dict[platform.strip()]\n",
    "    simplified_name = name.lower().strip()\n",
    "    # Getting rid of junk from the title\n",
    "    simplified_name = simplified_name.replace('\\'','').replace(',','').replace(':','').replace('/','')\n",
    "    simplified_name = simplified_name.replace('.','').replace(';','').replace('& ','')\n",
    "    simplified_name = simplified_name.replace(' ', '-')\n",
    "    \n",
    "    complete_url= '/'.join([base_url,full_platform,simplified_name,end])\n",
    "    return complete_url\n",
    "\n",
    "urls = []\n",
    "for row in meta_games.iterrows():\n",
    "    urls.append(URLMaker(row[1]['name'], row[1]['console']))\n",
    "urls[-1]\n",
    "meta_games[1100:1200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting extra details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_details = [\"ESRB Descriptors:\", \"Number of Online Players:\", \"Special Controllers:\", \"Number of Players:\"]\n",
    "\n",
    "for i, row in meta_games.iterrows():\n",
    "    print(row['name'])\n",
    "    game_metacritic_url = URLMaker(row['name'], row['console'], 'details')\n",
    "    game_req = requests.get(game_metacritic_url, headers = headers)\n",
    "    if game_req.status_code != 200:\n",
    "        print(game_req.status_code,game_metacritic_url)\n",
    "    else:\n",
    "        details_soup = BeautifulSoup(game_req.content, 'html.parser')\n",
    "        \n",
    "        # Doing publisher separately, first\n",
    "        publisher = details_soup.find_all('a', {'href': re.compile(r'/company')})[1].get_text().strip()\n",
    "        meta_games_copy.at[i,'publisher'] = publisher\n",
    "        \n",
    "        \n",
    "        game_details = details_soup.find_all('th', scope='row')\n",
    "        for detail in game_details:\n",
    "            if detail.get_text() in extra_details:\n",
    "                value = detail.next_sibling.get_text().strip()\n",
    "            elif detail.get_text() == \"Genre(s):\":\n",
    "                value = detail.next_sibling.next_sibling.get_text().split(',')\n",
    "                for j in range(len(value)):\n",
    "                    value[j] = value[j].strip()\n",
    "                value = np.unique(value)\n",
    "            else:\n",
    "                value = detail.next_sibling.next_sibling.get_text().strip()\n",
    "            key = detail.get_text().strip(':').lower()\n",
    "            meta_games_copy.at[i,key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the review scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for new_col in ['review scores', 'review summaries']:\n",
    "    meta_games_copy[new_col] = np.empty\n",
    "\n",
    "stopped = 0\n",
    "\n",
    "try:\n",
    "    for i, row in meta_games[stopped:].iterrows():\n",
    "        print(row['name'], i)\n",
    "        if i > 10:\n",
    "            break\n",
    "        game_metacritic_url = URLMaker(row['name'], row['console'], 'critic-reviews')\n",
    "        try: \n",
    "            game_req = requests.get(game_metacritic_url, headers = headers)\n",
    "        except:\n",
    "            meta_games_copy.to_csv('extra_scores_up_until_now.csv')\n",
    "            print(\"Request blocked, waiting 15 seconds.\")\n",
    "            time.sleep(15) \n",
    "            game_req = requests.get(game_metacritic_url, headers = headers)\n",
    "        if game_req.status_code != 200:\n",
    "            print(game_req.status_code,game_metacritic_url)\n",
    "        else:\n",
    "            reviews_soup = BeautifulSoup(game_req.content, 'html.parser')\n",
    "            review_metas = reviews_soup.find_all('li', {\"class\":\"review critic_review\"})\n",
    "            review_score_dict = {}\n",
    "            review_summary_dict = {}\n",
    "            for rev in review_metas:\n",
    "                try:\n",
    "                    cur_rev_critic = rev.find('div', {\"class\":\"review_critic\"}).find('a').get_text().strip()\n",
    "                except:\n",
    "                    cur_rev_critic = rev.find('div', {\"class\":\"review_critic\"}).find('div').get_text().strip()\n",
    "                cur_rev_summary = rev.find('div', {\"class\":\"review_body\"}).get_text().strip()\n",
    "                cur_rev_score = rev.find('div', {\"class\":\"review_grade\"}).get_text().strip()\n",
    "\n",
    "                review_summary_dict[cur_rev_critic] = cur_rev_summary\n",
    "                review_score_dict[cur_rev_critic] = cur_rev_score\n",
    "\n",
    "                meta_games_copy.at[i,'review scores'] = review_score_dict\n",
    "                meta_games_copy.at[i, 'review summaries'] = review_summary_dict\n",
    "except:\n",
    "    meta_games_copy.to_csv('extra_scores_up_until_now.csv')\n",
    "            \n",
    "meta_games_copy.to_csv('extra_scores_complete.csv')\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_games_copy.head(15)['review summaries'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting list of positive and negative adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjectives_4800 = requests.get(\"https://patternbasedwriting.com/elementary_writing_success/list-4800-adjectives/\")\n",
    "soup_4800 = BeautifulSoup(adjectives_4800.content, 'html.parser')\n",
    "words_4800 = soup_4800.find_all('table')[2].get_text()\n",
    "words_4800 = words_4800.split('\\n')\n",
    "words_4800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_adjectives = []\n",
    "banned_words = ['the', 'a', 'an', 'its', 'that', 'this', 'my', 'what', 'any', 'their', 'these', 'his', 'her',\n",
    "                'game', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten']\n",
    "for i in range(len(words_4800)):\n",
    "    if len(words_4800[i]) > 0:\n",
    "        cur_word = words_4800[i].split()[1]\n",
    "        if cur_word not in banned_words:\n",
    "            list_of_adjectives.append(cur_word)\n",
    "\n",
    "np.savetxt(\"Data/list_of_adjectives.txt\", list_of_adjectives, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive words\n",
    "with open('words-to-use-pos.txt', 'r') as f:\n",
    "    w2u_pos = [line.strip() for line in f]\n",
    "\n",
    "oliver_pos = ['absolutely','accepted','acclaimed','accomplish','accomplishment','achievement','action','active','admire','adorable','adventure','affirmative','affluent','agree','agreeable','amazing','angelic','appealing','approve','aptitude','attractive','awesome','beaming','beautiful','believe','beneficial','bliss','bountiful','bounty','brave','bravo','brilliant','bubbly','calm','celebrated','certain','champ','champion','charming','cheery','choice','classic','classical','clean','commend','composed','congratulation','constant','cool','courageous','creative','cute','dazzling','delight','delightful','distinguished','divine','earnest','easy','ecstatic','effective','effervescent','efficient','effortless','electrifying','elegant','enchanting','encouraging','endorsed','energetic','energized','engaging','enthusiastic','essential','esteemed','ethical','excellent','exciting','exquisite','fabulous','fair','familiar','famous','fantastic','favorable','fetching','fine','fitting','flourishing','fortunate','free','fresh','friendly','fun','funny','generous','genius','genuine','giving','glamorous','glowing','good','gorgeous','graceful','great','green','grin','growing','handsome','happy','harmonious','healing','healthy','hearty','heavenly','honest','honorable','honored','hug','idea','ideal','imaginative','imagine','impressive','independent','innovate','innovative','instant','instantaneous','instinctive','intellectual','intelligent','intuitive','inventive','jovial','joy','jubilant','keen','kind','knowing','knowledgeable','laugh','learned','legendary','light','lively','lovely','lucid','lucky','luminous','marvelous','masterful','meaningful','merit','meritorious','miraculous','motivating','moving','natural','nice','novel','now','nurturing','nutritious','okay','one','open','optimistic','paradise','perfect','phenomenal','pleasant','pleasurable','plentiful','poised','polished','popular','positive','powerful','prepared','pretty','principled','productive','progress','prominent','protected','proud','quality','quick','quiet','ready','reassuring','refined','refreshing','rejoice','reliable','remarkable','resounding','respected','restored','reward','rewarding','right','robust','safe','satisfactory','secure','seemly','simple','skilled','skillful','smile','soulful','sparkling','special','spirited','spiritual','stirring','stunning','stupendous','successsuccessful','sunny','super','superb','supporting','surprising','terrific','thorough','thrilling','thriving','tops','tranquil','transformative','transforming','trusting','truthful','unreal','unwavering','up','upbeat','upright','upstanding','valued','vibrant','victorious','victory','vigorous','virtuous','vital','vivacious','wealthy','welcome','well','whole','wholesome','willing','wonderful','wondrous','worthy','wow','yes','yummy','zeal','zealous']\n",
    "    \n",
    "combined_pos = list(np.unique(w2u_pos+oliver_pos))\n",
    "\n",
    "np.savetxt(\"Data/positive_adjectives.txt\", combined_pos, delimiter=\",\", fmt='%s')\n",
    "\n",
    "# Negative words \n",
    "\n",
    "with open('words-to-use-neg.txt', 'r') as f:\n",
    "    w2u_neg = [line.strip() for line in f]\n",
    "    \n",
    "oliver_neg = ['abysmal','adverse','alarming','angry','annoy','anxious','apathy','appalling','atrocious','awful','bad','banal','barbed','belligerent','bemoan','beneath','boring','broken','callous','clumsy','coarse','cold','cold','hearted','collapse','confused','contradictory','contrary','corrosive','corrupt','crazy','creepy','criminal','cruel','cry','cutting','damage','damaging','dastardly','dead','decaying','deformed','deny','deplorable','depressed','deprived','despicable','detrimental','dirty','disease','disgusting','disheveled','dishonest','dishonorable','dismal','distress','dreadful','dreary','enraged','eroding','evil','fail','faulty','fear','feeble','fight','filthy','foul','frighten','frightful','gawky','ghastly','grave','greed','grim','grimace','gross','grotesque','gruesome','guilty','haggard','hard','hard','hearted','harmful','hate','hideous','homely','horrendous','horrible','hostile','hurt','hurtful','icky','ignorant','ignore','ill','immature','imperfect','impossible','inane','inelegant','infernal','injure','injurious','insane','insidious','insipid','jealous','junky','lose','lousy','lumpy','malicious','mean','menacing','messy','misshapen','missing','misunderstood','moan','moldy','monstrous','naive','nasty','naughty','negate','negative','never','no','nobody','nondescript','nonsense','not','noxious','objectionable','odious','offensive','old','oppressive','pain','perturb','pessimistic','petty','plain','poisonous','poor','prejudice','questionable','quirky','quit','reject','renege','repellant','reptilian','repugnant','repulsive','revenge','revolting','rocky','rotten','rude','ruthless','sad','savage','scare','scary','scream','severe','shocking','shoddy','sick','sickening','sinister','slimy','smelly','sobbing','sorry','spiteful','sticky','stinky','stormy','stressful','stuck','stupid','substandard','suspect','suspicious','tense','terrible','terrifying','threatening','ugly','undermine','unfair','unfavorable','unhappy','unhealthy','unjust','unlucky','unpleasant','unsatisfactory','unsightly','untoward','unwanted','unwelcome','unwholesome','unwieldy','unwise','upset','vice','vicious','vile','villainous','vindictive','wary','weary','wicked','woeful','worthless','wound','yell','yucky','zero']\n",
    "\n",
    "combined_neg = np.unique(w2u_neg+oliver_neg)\n",
    "\n",
    "np.savetxt(\"Data/negative_adjectives.txt\", combined_neg, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the words not in the adjective list from the review words\n",
    "filtered_review_words = []\n",
    "for word in review_words:\n",
    "    if word in list_of_adjectives:\n",
    "        filtered_review_words.append(word)\n",
    "' '.join(filtered_review_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final scores data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_complete = pd.read_csv('C:/Users/Admin/Desktop/scores_complete.csv', index_col=0)\n",
    "original = pd.read_csv('../Data/result.csv')\n",
    "scores_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2 = original.join(scores_complete.drop_duplicates(['review summaries'])[['review scores','review summaries' ]])\n",
    "\n",
    "o2['userscore'] = o2['userscore'].replace('tbd', 'NaN').astype(float)\n",
    "o2.loc[(o2['console']=='PS3') & (o2['userscore']>8.3)]\n",
    "#o2.to_csv('scores_and_summaries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final details wrangling\n",
    "Need to delete players column (redundant to number of players and number of online players columns), remove the word 'Series' from all franchise cells, and properly delimit the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "details = pd.read_csv('../Data/extra_details_complete.csv',index_col=0,encoding='utf-8',dtype={'metascore':np.int,'genre(s)':'O'})\n",
    "details = details.drop(columns=['players'])\n",
    "pubs = np.unique(details['publisher'], return_counts=True)\n",
    "N = 10\n",
    "print('There are', len(pubs[0][pubs[1] > N]),'publishers with more than', N, 'games')\n",
    "devs = np.unique(details['developer'], return_counts=True)\n",
    "print('There are', len(devs[0][devs[1] > N]),'developers with more than', N, 'games')\n",
    "\n",
    "#gens = details['genre(s)'][1].replace(' u\\'', ',\\'').replace('[u','[')\n",
    "\n",
    "\n",
    "details['franchise'] = details['franchise'].str.replace(' Series', '').replace(np.nan,'')\n",
    "details = details.replace('<built-in function empty>', ' ')\n",
    "details['genre(s)'] = details['genre(s)'].str.replace(' u\\'', ', \\'').str.replace('u\\'','\\'').str.replace('\\'', '').str.replace('\\]','').str.replace('\\[','')\n",
    "#details.to_csv('./extra_details_complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling user comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_comments = pd.read_csv('../Data/metacritic_game_user_comments.csv', index_col=0, dtype=str)\n",
    "critic_reviews = pd.read_csv('../Data/scores_and_summaries.csv',index_col=0)\n",
    "critic_reviews_copy = critic_reviews.copy()\n",
    "user_comments_copy = user_comments.copy().drop('Username', axis=1)\n",
    "user_comments_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think unnecessary\n",
    "\n",
    "\n",
    "# import unicodedata\n",
    "# for i, row in user_comments.iterrows():\n",
    "#     if type(row['Comment']) != str:\n",
    "#         print(user_comments_copy.iloc[i]['Comment'])\n",
    "#         continue\n",
    "#     else:\n",
    "#         user_comments_copy.iloc[i]['Comment'] = unicodedata.normalize('NFKD',row['Comment']).encode('ascii', 'ignore').decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_comments_copy.fillna(value = '', inplace=True)\n",
    "user_comments_copy.isna().values.any()\n",
    "#user_comments_copy.loc[15:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_comments = user_comments_copy.groupby(['Title', 'Platform']).agg({'Userscore':', '.join, \n",
    "                             'Comment': ', '.join}).reset_index()\n",
    "grouped_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_consoles = np.unique(user_comments['Platform'])\n",
    "critics_consoles = np.unique(critic_reviews['console'])\n",
    "print(comments_consoles)\n",
    "print(critics_consoles)\n",
    "gro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "console_convert_dict = {'Dreamcast':'DC',\n",
    "                        'GameBoyAdvance':'GBA',\n",
    "                        'GameCube':'GC',\n",
    "                        'Nintendo64':'N64',\n",
    "                        'PlayStation':'PS',\n",
    "                        'PlayStation2':'PS2',\n",
    "                        'PlayStation3':'PS3',\n",
    "                        'PlayStation4':'PS4',\n",
    "                        'PlayStationVita':'VITA',\n",
    "                        'Wii':'WII',\n",
    "                        'WiiU':'WIIU',\n",
    "                        'Xbox':'XBOX',\n",
    "                        'Xbox360':'X360',\n",
    "                        'XboxOne':'XONE',\n",
    "                        'not specified':'NA'}\n",
    "\n",
    "grouped_comments_copy = grouped_comments.copy()\n",
    "\n",
    "for i, row in grouped_comments.iterrows():\n",
    "    platform = row['Platform']\n",
    "    if platform in console_convert_dict.keys():\n",
    "        grouped_comments_copy.loc[i]['Platform'] = console_convert_dict[platform]\n",
    "    else:\n",
    "        continue\n",
    "grouped_comments_copy.rename(index=str, columns={\"Platform\": \"console\",\n",
    "                                                 \"Title\": \"name\",\n",
    "                                                 'Userscore': 'user scores',\n",
    "                                                 'Comment':'user comments'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(critic_reviews_copy.columns)\n",
    "print(grouped_comments_copy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.merge(critic_reviews_copy, grouped_comments_copy,on=['name','console'], how='left')\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "combined_copy = combined.copy()\n",
    "for i,row in combined.iterrows():\n",
    "    try:\n",
    "        combined_copy.at[i,'review scores'] = re.sub(r'[a-zA-Z]+',',',re.sub(r'[\\W+]', '',combined.loc[i,'review scores']))[1:]\n",
    "        combined_copy.at[i,'review summaries'] = ' '.join(list(eval(combined.loc[i,'review summaries']).values()))\n",
    "    except:\n",
    "        print(combined_copy.loc[i,'review scores'])\n",
    "        print(combined_copy.loc[i,'review summaries'])\n",
    "        combined_copy.at[i,'review scores'] = np.nan\n",
    "        combined_copy.at[i,'review summaries'] = np.nan\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_copy.loc[1,'review summaries']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#combined_copy.to_csv('../Data/critic_and_users_full_text.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering for only adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_4800 = np.loadtxt('../Data/list_of_adjectives.txt',delimiter=',',dtype='str')\n",
    "pos_words = np.loadtxt('../Data/positive_adjectives.txt',delimiter=',',dtype='str')\n",
    "neg_words = np.loadtxt('../Data/negative_adjectives.txt',delimiter=',',dtype='str')\n",
    "all_adj = frozenset(list(np.union1d(np.union1d(pos_words,neg_words),adj_4800)))\n",
    "\n",
    "only_adj_df = combined_copy.copy()\n",
    "only_adj_df['user adjectives'] = ''\n",
    "only_adj_df['critic adjectives'] = ''\n",
    "\n",
    "for i, row in combined_copy.iterrows():\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "    try:\n",
    "        critic_words = re.sub(r'[^a-z\\s\\-]', '',only_adj_df.loc[i,'review summaries'].lower()).split(' ')\n",
    "        user_adj_gen = [c_word for c_word in critic_words if c_word in all_adj]\n",
    "        only_adj_df.at[i,'critic adjectives'] = ','.join(list(user_adj_gen))\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        user_words = re.sub(r'[^a-z\\s\\-]', '',only_adj_df.loc[i,'user comments'].lower()).split(' ')\n",
    "        user_adj_gen = (u_word for u_word in user_words if u_word in all_adj)\n",
    "        only_adj_df.at[i,'user adjectives'] = ','.join(list(user_adj_gen))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = re.sub(r'[^a-z\\s\\-]', '',only_adj_df.loc[0,'review summaries'].lower()).split(' ')\n",
    "found = [i for i in words if i in all_adj]\n",
    "print(list(found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only_adj_df = only_adj_df.drop('review summaries', axis=1)\n",
    "# only_adj_df = only_adj_df.drop('user comments', axis=1)\n",
    "only_adj_df.head(20)\n",
    "#only_adj_df.to_csv('../Data/critic_and_users_adjective_only.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
